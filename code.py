# -*- coding: utf-8 -*-
"""DMproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qeaxl8mgzmvj9t__W1kt_EQhViCowid4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("/content/train.csv")
df.head()

df.shape

"""# **Data Cleaning**"""

# Check for missing values and duplicates
df.isnull().sum()

# Drop any nan
df.dropna(inplace=True) #

df.isnull().sum() #RECHECKING

df.dtypes

df.duplicated().sum()  # How many full duplicate rows?

df.drop_duplicates(inplace=True)

df.duplicated().sum() #recheck

df['Category'].value_counts()

"""# **Feature Engineering**"""

# Filter categories
crime_mapping = {
    'ASSAULT': 'Violent',
    'ROBBERY': 'Violent',
    'BATTERY': 'Violent',
    'LARCENY/THEFT': 'Property',
    'BURGLARY': 'Property',
    'VEHICLE THEFT': 'Property',
    'TRESPASS': 'Property',
    'DRUG/NARCOTIC': 'Drug',
    'DRUNKENNESS': 'Drug',
}
df = df[df['Category'].isin(crime_mapping.keys())]
df['CrimeGroup'] = df['Category'].map(crime_mapping)

# Convert date column and extract features
df['Dates'] = pd.to_datetime(df['Dates'])
df['Hour'] = df['Dates'].dt.hour
df['DayOfWeek'] = df['Dates'].dt.dayofweek
df['Month'] = df['Dates'].dt.month
# Encode PdDistrict column
le_district = LabelEncoder()
df['PdDistrictEncoded'] = le_district.fit_transform(df['PdDistrict'])
le_group = LabelEncoder() #encode the target
df['CrimeGroupEncoded'] = le_group.fit_transform(df['CrimeGroup'])

df.drop(['Dates', 'Category', 'PdDistrict', 'Descript', 'Resolution', 'Address'], axis=1, inplace=True)

X = df[['Hour', 'DayOfWeek', 'Month', 'X', 'Y', 'PdDistrictEncoded']]
y = df['CrimeGroupEncoded']

"""# **Exploratory Data Analysis**"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(16, 6))
sns.countplot(x='Category', data=df, order=df['Category'].value_counts().index)
plt.xticks(rotation=90)  # Rotate x labels so they donâ€™t overlap
plt.title('Distribution of Crime Categories (Real Names)')
plt.xlabel('Crime Category')
plt.ylabel('Count')
plt.show()

# Hourly Crime Trends
plt.figure(figsize=(12, 5))
sns.histplot(df['Hour'], bins=24, kde=True, color='#3498db')
plt.title('Crimes by Hour of Day')
plt.xlabel('Hour')
plt.show()
plt.figure(figsize=(12, 5))
sns.countplot(x='Hour', data=df)
plt.title('Crimes by Hour of Day')
plt.xlabel('Hour (0 = midnight)')
plt.ylabel('Number of Crimes')
plt.show()

plt.figure(figsize=(10, 5))
sns.countplot(x='DayOfWeek', data=df)
plt.title('Crimes by Day of the Week') #monday = 0, sunday= 6
plt.xlabel('Day of Week')
plt.ylabel('Crime Count')
plt.show()

plt.figure(figsize=(14, 5))
sns.countplot(x='PdDistrict', data=df, order=df['PdDistrict'].value_counts().index)
plt.title('Crimes by Police District')
plt.xlabel('District')
plt.ylabel('Crime Count')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 8))
sns.scatterplot(x='X', y='Y', hue='Category', data=df, alpha=0.8, s=20, legend= False)
plt.title('Crime Map Colored by Type')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()

"""# **Clustering with KMeans**"""

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Use X, Y, Hour for clustering, clustering on location and time
cluster_data = df[['X', 'Y', 'Hour']]

scaler = StandardScaler()
cluster_data_scaled = scaler.fit_transform(cluster_data)

kmeans = KMeans(n_clusters=5, random_state=42)
df['Cluster'] = kmeans.fit_predict(cluster_data_scaled)

plt.figure(figsize=(10, 8))
sns.scatterplot(x='X', y='Y', hue='Cluster', data=df, palette='tab10', alpha=0.5)
plt.title('Crime Clusters Based on Location and Time')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.legend(title='Cluster')
plt.show()

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Fit KMeans on location data
cluster_data = df[['X', 'Y']]
kmeans = KMeans(n_clusters=5, random_state=42)
labels = kmeans.fit_predict(cluster_data)

# Silhouette Score
score = silhouette_score(cluster_data, labels)
print(f"Silhouette Score: {score:.2f}")  # Clean 2-decimal output

"""# **Model Evaluation**"""

from sklearn.model_selection import train_test_split

# Features and Target
X = df[['Hour', 'DayOfWeek', 'Month', 'X', 'Y', 'PdDistrictEncoded']]
y = df['CrimeGroupEncoded']

# Split into 80% train / 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

# Train a Decision Tree
dtree = DecisionTreeClassifier(max_depth=10, random_state=42)
dtree.fit(X_train, y_train)

# Predict
y_pred_dt = dtree.predict(X_test)

# Evaluate
print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt, zero_division=0))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Train
clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
clf.fit(X_train, y_train)

# Predict
y_pred = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
